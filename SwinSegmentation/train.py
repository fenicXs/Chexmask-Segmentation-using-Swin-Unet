"""
Training script for Swin-UNet segmentation model
"""

import os
import sys
import time
import argparse
from tqdm import tqdm
import numpy as np
import torch
import torch.nn as nn
from torch.amp import autocast, GradScaler  # Updated import for PyTorch 2.0+
from torch.optim import Adam, AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, StepLR

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import config
from models.swin_unet import build_swin_unet
from models.swin_unet_pretrained import build_pretrained_swin_unet
from utils.dataset import get_dataloaders
from utils.losses import get_loss_function, SegmentationMetrics
from utils.visualization import visualize_batch, plot_training_curves


class Trainer:
    """Trainer class for segmentation model"""
    
    def __init__(self, config):
        self.config = config
        self.device = torch.device(config.DEVICE if torch.cuda.is_available() else 'cpu')
        print(f"Using device: {self.device}")
        
        # Create experiment directory
        self.exp_dir = os.path.join(config.CHECKPOINT_DIR, config.EXPERIMENT_NAME)
        self.output_dir = os.path.join(config.OUTPUT_DIR, config.EXPERIMENT_NAME)
        os.makedirs(self.exp_dir, exist_ok=True)
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Build model
        print("Building model...")
        if getattr(config, 'USE_PRETRAINED', False):
            print("Using pretrained Swin-UNet model")
            self.model = build_pretrained_swin_unet(config)
        else:
            print("Using custom Swin-UNet model")
            self.model = build_swin_unet(config.SWIN_CONFIG)
        self.model = self.model.to(self.device)
        variant = getattr(config, 'SWIN_VARIANT', 'tiny')
        embed_dim = config.SWIN_CONFIG.get('embed_dim')
        depths = config.SWIN_CONFIG.get('depths')
        print(
            f"Loaded backbone variant: Swin-{variant} | embed_dim={embed_dim} | depths={depths}"
        )
        
        # Multi-GPU
        if config.USE_MULTI_GPU and torch.cuda.device_count() > 1:
            print(f"Using {torch.cuda.device_count()} GPUs")
            self.model = nn.DataParallel(self.model)
        
        # Print model info
        num_params = sum(p.numel() for p in self.model.parameters()) / 1e6
        print(f"Number of parameters: {num_params:.2f}M")
        
        # Loss function
        self.criterion = get_loss_function(config)
        self.criterion = self.criterion.to(self.device)
        
        # Optimizer
        if config.OPTIMIZER == 'adam':
            self.optimizer = Adam(
                self.model.parameters(),
                lr=config.LEARNING_RATE,
                weight_decay=config.WEIGHT_DECAY
            )
        elif config.OPTIMIZER == 'adamw':
            self.optimizer = AdamW(
                self.model.parameters(),
                lr=config.LEARNING_RATE,
                weight_decay=config.WEIGHT_DECAY
            )
        else:
            raise ValueError(f"Unknown optimizer: {config.OPTIMIZER}")
        
        # Learning rate scheduler
        self.scheduler = None
        if config.USE_SCHEDULER:
            if config.SCHEDULER_TYPE == 'cosine':
                self.scheduler = CosineAnnealingLR(
                    self.optimizer,
                    T_max=config.NUM_EPOCHS,
                    eta_min=1e-6
                )
            elif config.SCHEDULER_TYPE == 'plateau':
                self.scheduler = ReduceLROnPlateau(
                    self.optimizer,
                    mode='min',
                    factor=config.SCHEDULER_FACTOR,
                    patience=config.SCHEDULER_PATIENCE,
                    verbose=True
                )
            elif config.SCHEDULER_TYPE == 'step':
                self.scheduler = StepLR(
                    self.optimizer,
                    step_size=config.NUM_EPOCHS // 3,
                    gamma=0.1
                )
        
        # AMP scaler - updated for PyTorch 2.0+
        self.scaler = GradScaler('cuda') if config.USE_AMP else None
        
        # Gradient accumulation
        self.grad_accum_steps = getattr(config, 'GRADIENT_ACCUMULATION_STEPS', 1)
        self.grad_clip_norm = getattr(config, 'GRADIENT_CLIP_NORM', None)
        self.warmup_epochs = getattr(config, 'WARMUP_EPOCHS', 0)
        
        # Pretrained model settings
        self.use_pretrained = getattr(config, 'USE_PRETRAINED', False)
        self.freeze_encoder_epochs = getattr(config, 'FREEZE_ENCODER_EPOCHS', 0)
        
        # Data loaders
        print("Creating data loaders...")
        self.train_loader, self.val_loader, self.test_loader = get_dataloaders(config)
        
        # Training history
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'train_dice': [],
            'val_dice': [],
            'train_iou': [],
            'val_iou': [],
            'lr': []
        }
        
        # Best metrics
        self.best_val_dice = 0.0
        self.best_epoch = 0
        self.epochs_without_improvement = 0
        
        # Visualization data storage
        self.last_vis_data = None
    
    def train_epoch(self, epoch):
        """Train for one epoch"""
        self.model.train()
        
        epoch_loss = 0.0
        metrics = SegmentationMetrics(self.config.NUM_CLASSES, self.device)
        
        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch+1}/{self.config.NUM_EPOCHS} [Train]")
        
        # Learning rate warmup
        if epoch < self.warmup_epochs:
            lr_scale = (epoch + 1) / self.warmup_epochs
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = self.config.LEARNING_RATE * lr_scale
        
        # Unfreeze encoder after specified epochs
        if self.use_pretrained and epoch == self.freeze_encoder_epochs and hasattr(self.model, 'unfreeze_encoder'):
            print(f"Unfreezing encoder at epoch {epoch + 1}")
            self.model.unfreeze_encoder()
        
        for batch_idx, batch in enumerate(pbar):
            images = batch['image'].to(self.device)
            masks = batch['mask'].to(self.device)
            
            # Forward pass
            if self.config.USE_AMP:
                with autocast('cuda'):  # Specify device for PyTorch 2.0+
                    outputs = self.model(images)
                    loss = self.criterion(outputs, masks)
                    loss = loss / self.grad_accum_steps
                
                # Backward pass
                self.scaler.scale(loss).backward()
                
                # Gradient accumulation
                if (batch_idx + 1) % self.grad_accum_steps == 0:
                    if self.grad_clip_norm is not None:
                        self.scaler.unscale_(self.optimizer)
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip_norm)
                    
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad()
            else:
                outputs = self.model(images)
                loss = self.criterion(outputs, masks)
                loss = loss / self.grad_accum_steps
                
                # Backward pass
                loss.backward()
                
                # Gradient accumulation
                if (batch_idx + 1) % self.grad_accum_steps == 0:
                    if self.grad_clip_norm is not None:
                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip_norm)
                    
                    self.optimizer.step()
                    self.optimizer.zero_grad()
            
            # Update metrics
            epoch_loss += loss.item() * self.grad_accum_steps
            metrics.update(outputs.detach(), masks)
            
            # Update progress bar
            if batch_idx % self.config.LOG_FREQ == 0:
                pbar.set_postfix({'loss': loss.item() * self.grad_accum_steps})
        
        # Compute epoch metrics
        avg_loss = epoch_loss / len(self.train_loader)
        epoch_metrics = metrics.get_mean_metrics()
        
        return avg_loss, epoch_metrics
    
    def validate(self, epoch):
        """Validate the model"""
        self.model.eval()
        
        epoch_loss = 0.0
        metrics = SegmentationMetrics(self.config.NUM_CLASSES, self.device)
        
        # Store some samples for visualization
        vis_images = []
        vis_masks = []
        vis_preds = []
        
        pbar = tqdm(self.val_loader, desc=f"Epoch {epoch+1}/{self.config.NUM_EPOCHS} [Val]")
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(pbar):
                images = batch['image'].to(self.device)
                masks = batch['mask'].to(self.device)
                
                # Forward pass
                if self.config.USE_AMP:
                    with autocast('cuda'):  # Specify device for PyTorch 2.0+
                        outputs = self.model(images)
                        loss = self.criterion(outputs, masks)
                else:
                    outputs = self.model(images)
                    loss = self.criterion(outputs, masks)
                
                # Update metrics
                epoch_loss += loss.item()
                metrics.update(outputs, masks)
                
                # Store samples for visualization
                if batch_idx == 0:
                    vis_images = images[:4].cpu()
                    vis_masks = masks[:4].cpu()
                    vis_preds = torch.argmax(outputs[:4], dim=1).cpu()
                
                pbar.set_postfix({'loss': loss.item()})
        
        # Compute epoch metrics
        avg_loss = epoch_loss / len(self.val_loader)
        epoch_metrics = metrics.get_mean_metrics()
        
        # Store visualization data for potential use in main training loop
        self.last_vis_data = {
            'images': vis_images,
            'masks': vis_masks, 
            'preds': vis_preds,
            'epoch': epoch
        }
        
        # Visualize predictions at specified frequency
        if self.config.SAVE_VISUALIZATIONS and epoch % self.config.VIS_FREQ == 0:
            vis_path = os.path.join(self.output_dir, f'epoch_{epoch+1}_predictions.png')
            visualize_batch(vis_images, vis_masks, vis_preds, num_samples=4, save_path=vis_path)
            print(f"ðŸ“Š Saved predictions visualization: {vis_path}")
        
        return avg_loss, epoch_metrics
    
    def save_checkpoint(self, epoch, is_best=False):
        """Save model checkpoint"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'best_val_dice': self.best_val_dice,
            'history': self.history,
            'config': self.config.SWIN_CONFIG
        }
        
        # Save latest checkpoint
        checkpoint_path = os.path.join(self.exp_dir, f'checkpoint_epoch_{epoch+1}.pth')
        torch.save(checkpoint, checkpoint_path)
        
        # Save best checkpoint
        if is_best:
            best_path = os.path.join(self.exp_dir, 'best_model.pth')
            torch.save(checkpoint, best_path)
            print(f"âœ“ Saved best model with Dice: {self.best_val_dice:.4f}")
        
        # Remove old checkpoints (keep only recent ones)
        self._cleanup_checkpoints()
    
    def _cleanup_checkpoints(self):
        """Keep only the N most recent checkpoints"""
        checkpoints = [f for f in os.listdir(self.exp_dir) if f.startswith('checkpoint_epoch_')]
        checkpoints.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))
        
        if len(checkpoints) > self.config.KEEP_BEST_N:
            for ckpt in checkpoints[:-self.config.KEEP_BEST_N]:
                os.remove(os.path.join(self.exp_dir, ckpt))
    
    def train(self):
        """Main training loop"""
        print("\nStarting training...")
        print(f"Experiment: {self.config.EXPERIMENT_NAME}")
        print(f"Device: {self.device}")
        print(f"Epochs: {self.config.NUM_EPOCHS}")
        print(f"Batch size: {self.config.BATCH_SIZE}")
        print(f"Learning rate: {self.config.LEARNING_RATE}")
        print(f"Train samples: {len(self.train_loader.dataset)}")
        print(f"Val samples: {len(self.val_loader.dataset)}")
        print("-" * 50)
        
        start_time = time.time()
        
        for epoch in range(self.config.NUM_EPOCHS):
            epoch_start = time.time()
            
            # Train
            train_loss, train_metrics = self.train_epoch(epoch)
            
            # Validate
            if (epoch + 1) % self.config.VAL_FREQ == 0:
                val_loss, val_metrics = self.validate(epoch)
            else:
                val_loss, val_metrics = None, None
            
            # Update learning rate
            if self.scheduler is not None:
                if self.config.SCHEDULER_TYPE == 'plateau':
                    self.scheduler.step(val_loss if val_loss else train_loss)
                else:
                    self.scheduler.step()
            
            # Get current learning rate
            current_lr = self.optimizer.param_groups[0]['lr']
            
            # Update history
            self.history['train_loss'].append(train_loss)
            self.history['train_dice'].append(train_metrics['mean_dice'])
            self.history['train_iou'].append(train_metrics['mean_iou'])
            self.history['lr'].append(current_lr)
            
            if val_loss is not None:
                self.history['val_loss'].append(val_loss)
                self.history['val_dice'].append(val_metrics['mean_dice'])
                self.history['val_iou'].append(val_metrics['mean_iou'])
            
            # Plot and save training curves after every epoch (overwrites previous)
            plot_path = os.path.join(self.output_dir, 'training_curves.png')
            try:
                plot_training_curves(self.history, save_path=plot_path)
            except Exception as e:
                print(f"Warning: Could not save training curves: {e}")
            
            # Print epoch summary
            epoch_time = time.time() - epoch_start
            print(f"\nEpoch {epoch+1}/{self.config.NUM_EPOCHS} - {epoch_time:.1f}s")
            print(f"  Train Loss: {train_loss:.4f} | Dice: {train_metrics['mean_dice']:.4f} | IoU: {train_metrics['mean_iou']:.4f}")
            if val_loss is not None:
                print(f"  Val   Loss: {val_loss:.4f} | Dice: {val_metrics['mean_dice']:.4f} | IoU: {val_metrics['mean_iou']:.4f}")
                print(f"  LR: {current_lr:.6f}")
            
            # Check if best model
            is_best = False
            if val_metrics is not None and val_metrics['mean_dice'] > self.best_val_dice:
                self.best_val_dice = val_metrics['mean_dice']
                self.best_epoch = epoch
                is_best = True
                self.epochs_without_improvement = 0
                
                # Generate visualization on improvement (even if not at regular interval)
                if self.config.SAVE_VISUALIZATIONS and self.config.VIS_ON_IMPROVEMENT and hasattr(self, 'last_vis_data'):
                    vis_path = os.path.join(self.output_dir, f'epoch_{epoch+1}_BEST_predictions.png')
                    visualize_batch(
                        self.last_vis_data['images'], 
                        self.last_vis_data['masks'], 
                        self.last_vis_data['preds'], 
                        num_samples=4, 
                        save_path=vis_path
                    )
                    print(f"ðŸ† NEW BEST MODEL! Saved predictions: {vis_path}")
            else:
                self.epochs_without_improvement += 1
            
            # Save checkpoint
            if (epoch + 1) % self.config.SAVE_EVERY == 0 or is_best:
                self.save_checkpoint(epoch, is_best)
            
            # Early stopping
            if self.config.USE_EARLY_STOPPING and self.epochs_without_improvement >= self.config.EARLY_STOPPING_PATIENCE:
                print(f"\nEarly stopping triggered after {epoch+1} epochs")
                print(f"Best validation Dice: {self.best_val_dice:.4f} at epoch {self.best_epoch+1}")
                break
        
        # Training complete
        total_time = time.time() - start_time
        print("\n" + "="*50)
        print(f"Training complete! Total time: {total_time/3600:.2f} hours")
        print(f"Best validation Dice: {self.best_val_dice:.4f} at epoch {self.best_epoch+1}")
        print(f"Training curves saved to {os.path.join(self.output_dir, 'training_curves.png')}")


def main():
    parser = argparse.ArgumentParser(description='Train Swin-UNet for chest X-ray segmentation')
    parser.add_argument('--config', type=str, default='config', help='Config module name')
    parser.add_argument('--resume', type=str, default=None, help='Path to checkpoint to resume from')
    args = parser.parse_args()
    
    # Create trainer
    trainer = Trainer(config)
    
    # Resume from checkpoint if specified
    if args.resume:
        print(f"Resuming from checkpoint: {args.resume}")
        checkpoint = torch.load(args.resume)
        trainer.model.load_state_dict(checkpoint['model_state_dict'])
        trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        if trainer.scheduler and checkpoint['scheduler_state_dict']:
            trainer.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        trainer.history = checkpoint['history']
        trainer.best_val_dice = checkpoint['best_val_dice']
    
    # Train
    trainer.train()


if __name__ == '__main__':
    main()
